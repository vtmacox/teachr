---
title: "Advanced R"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(exercise.checker = checkr::checkr_tutor)
```


## Objectives

If you have completed the `Learning R` tutorial, then you are familiar with the basics of how to use **R**.  In this tutorial we will build on these skills and learn several advanced **R** coding techniques.  Specifically, this tutorial will focus on:

- Using the `dplyr` package for advance data manipulation and data wrangling
- Using the `ggoplot2` package to create graphs and figures
- Using **RStudio** to create dynamic reproducible reports

## Welcome to the Tidyverse!

In the last tutorial, we learned about **R** and how to use base **R** code and functions to read in and manipulate data. While this code is very useful, it can be somewhat difficult to use.  For example, when you reference variables in a dataframe, you have to first reference the dataframe, then use the `$` symbol, and then reference the variable.  This is cumbersome, especially when you have to reference multiple variables.  Additionally, **R** code is difficult to read.  Often functions are nested within one another and in order to understand what the code is trying to do, you have to read the inside most function first, then read each subsequent outer function.  

Fortunately, there are a collection of packages that make **R** easier to read and easier to write.  Hadely Wickham, a data scientist at **RStudio** and adjunct professor of Psychology at Rice University, has created a collection of packages for enhancing **R** code called `tidyverse` which is a package that installs and loads a series of packages.  We are going to focus on a few of these packages.

The first package we will be using is the `dplyr` package.  This package is useful for "data wrangling" or manipulating data.  Let's start by installing and loading the `tidyverse` package which will install and load the `dplyr` package.

```{r load_package, exercise = TRUE}
# Install and load the tidyverse package here


```


```{r load_package-hint}
install.packages("tidyverse")

library(tidyverse)

```

### Creating variables with `dplry`

Now that the package is loaded, let's redo an exercise we did in the last tutorial.  Let's go back to the `starwars` dataframe and create a BMI variable. 

In the space below, create the BMI variable the way you were taught in the last tutorial.

```{r bmi1, exercise = TRUE,  exercise.eval = TRUE}


```


```{r bmi1-solution}
starwars$bmi <- starwars$mass / (starwars$height / 100)^2

```

In the code you created, we have to make a reference to the `starwars` dataframe each time we reference a variable, even the new one we are creating.  This is unnecessary with using `dplyr`

`dplyr` uses a method called *piping* to string together data and commands.  Let's break down an example.  Below is the code that produces the same results as above, but uses `dplyr`.

```{r, echo=TRUE}
starwars <- starwars %>% 
  mutate(bmi = mass / (height / 100)^2)
  
```

In the code above we start with signing a new value to the dataframe `starwars`.  Essentially we are just overwriting this dataframe with the same dataframe plus the new variable we will create.  To the right of the assign symbol, we reference the data that we will be using--in this case the `starwars` dataframe.  The `%>%` symbol is part of the piping system.  It tells **R** that the code on the following lines uses whatever came before that symbol.  On the next line we use the `mutate()` function from `dplyr`.  This function creates variables.  In the function we specify the variable name we want to create and set it equal to the equation for calculating BMIs.  Notice that we don't have to reference the starwars dataframe at any point following the first reference, yet we still know what dataframe we are referencing from the first line of code.

While we didn't save a lot of time and space for creating one variable, if you were creating several variables, this would be a huge time saver.  

### Subsetting data with `dplyr`

Another nice thing about `dplyr` is that you can perform multiple operations/functions at the same time.  

In the last tutorial we calculated the bmi of the participants and then we subset the data to only include obese participants.  In the code below we will do this and we will limit the data to only the `height`, `mass`, and `bmi` variables.  

```{r bmi2, echo=TRUE}
starwars2 <- starwars %>% 
  mutate(bmi = mass/(height/100)^2,
         obese = if_else(bmi >= 30, 1, 0)) %>% 
  dplyr::filter(obese == 1) %>% 
  dplyr::select(height, mass, bmi)

head(starwars2)

```

The code above builds on the previous code.  We have the same code except now we are creating another variable called `obese`.  This variable is created in the `mutate()` function but we separate this variable from the previous with a `,`.  Once we have finished with the `mutate()` function we use the `%>%` to indicate we are using another function.  Next we use the `filter()` function from dplyr to say we want to limit our data to only obese people using the `obese` variable we just created.  The final function is `select()` and we list the variables we want in our final dataset. Notice that we don't have to have the variable names in quote for this function.  

You will notice that there is a `dplyr::` prefix to the `filter()` and `select()` functions.  This is a way to specify the package you want the function to come from.  In the last tutorial I mentioned that functions from different packages can have the same name.  This is the case for the `filter()` and `select()` functions.  By using `dplyr::` prefix we make sure that we are using functions from the `dplyr` package.  We could have done this with the `mutate()` function too but we didn't need to.  Additionally, using the `::` when calling a function means you don't have to load a package using `library()`.  This is useful if you aren't using a function often and don't want to have a ton of libraries loaded.

You can use non `dplyr` function within the piping framework.  For example 

```{r, echo=TRUE}
starwars %>% 
  mutate(bmi = mass/(height/100)^2,
         obese = if_else(bmi >= 30, 1, 0)) %>% 
  dplyr::filter(obese == 1) %>% 
  dplyr::select(height, mass, bmi) %>% 
  lapply(., function(x) mean(x, na.rm = T)) %>% 
  as.data.frame(.)

```

The second to last line of code uses the `lapply()` function, but the data argument of the function has the `.` symbol which means that we want to use the data that has been piped to this point.  The data is the filtered data with only the variables we selected. The last line turns the result of the previous line into a dataframe.  You can see that the piping allows us to clearly follow all the steps of how the data were manipulated in a linear fashion.

We actually could have created the same dataframe using functions in `dplyr`.  We could use the the `summarise()` function, but we would have to create variable names for each variable we want.  Instead we could use the `summarise_all()` function which will apply the summary functions we select to all the variables.

```{r, echo=TRUE}
starwars %>% 
  mutate(bmi = mass/(height/100)^2,
         obese = if_else(bmi >= 30, 1, 0)) %>% 
  dplyr::filter(obese == 1) %>% 
  dplyr::select(height, mass, bmi) %>% 
  summarise_all(., funs(mean(., na.rm = T)))

```


The first argument of `summarise_all()` is the data, and the second argument is the function we want applied to all the variables.  In this case, it is `mean()`.  We also passed the `na.rm = T` argument in the `mean()` function to deal with the missing data.

We could have also passed a number of other functions if we wanted (e.g., `sd()`, `median()`, etc.), and `dplyr` would have just kept adding variables to the dataframe and added a suffix to the variable names with the function that was used, such as `height_mean`.  

I'll show you how to create a table of descriptive stats using `dplyr`.  **NOTE:** While the code itself is very simple, how it is used is quite complicated.  I just want to show that it can be done, but I don't expect you to know how to do this. 

```{r, echo=TRUE}
starwars %>% 
  mutate(bmi = mass/(height/100)^2,
         obese = if_else(bmi >= 30, 1, 0)) %>% 
  dplyr::filter(obese == 1) %>% 
  dplyr::select(height, mass, bmi) %>% 
  dplyr::summarise_all(funs(mean, median, min, max, 
                            range = diff(range(., na.rm = T)), 
                            missing = sum(is.na(.)),
                            n = sum(!is.na(.))),
                       na.rm = T) %>% 
  tidyr::gather(stat, val) %>% 
  tidyr::separate(stat, into = c("var", "stat"), sep = "_") %>% 
  tidyr::spread(stat, val)

```
  
In the code above you can see we use the `summarise_all()` function, but this time we include a lot more arguments.  You can see that we include the `max()`, `mean()`,` median()`, and` min()` functions.  We also create several variables using several functions.  W create `missing` by summing all of the TRUE values of `is.na()`.  We create `range` by using the `diff()` function and the range() function.  Lastly, we create `n` by summing `!is.na()`.  When there is an `!` in front of a function that returns `TRUE` or `FALSE` values, the opposite values are returned.  Essentially `!` is asking when the values are NOT `TRUE`.  The resulting object is a dataframe with 1 row and 21 columns.  The columns are the variables with the suffix representing the stat that was used.  This isn't very efficient.  Instead we want 1 row for each variable and 1 column for each statistic.  Since we have 3 variables and 7 stats, we want a 3 X 7 dataframe.  

The `gather()` function turns the 1 X 21 dataframe into a 21 X 2 dataframe with the variable/stat indicator as one variable called `stat` and the value of that statistic for that variable as the second variable called `val`.  The `separate()` function splits the new `stat` variable into 2 variables using the `_` as the place where the split occurs.  This gives us a 21 X 3 data frame with one variable called `var` which is the variable from the original dataframe, a variable called `stat` which is the statistic that was performed on the variable, and a variable `val` which is the value of that statistic on that variable.  The `spread()` function is the compliment of `gather()`.  It creates a new variable for each unique value of `stat` and uses `var` implicitly as grouping factor to assign the proper value to each statistic at each variable. The function knew to use `var` as the grouping variable because there are only 3 variables in the dataframe and we specified  2 of them for other arguments, so it assumes any non-assigned variables are grouping variables.  This results in a 3 X 7 dataframe where the rows represent the variables and the columns represent the statistics.  The elements are the values of each statistic for each variable.  

There are many ways to get the same outcome when you use code.  No one way is "correct" but you should strive to make your code as efficient and easy to read as possible.  By efficient, I mean use as few lines of code as possible and use code that gets the job done as fast as possible.  As you learn to code don't worry about efficiency.  That will come with practice.

### Practicing with `dplyr`

Now lets have you try to use `dplyr` and piping.  Use piping and `dplyr` functions to filter only participants with brown hair and output the frequencies for the gender, species, and home world for those characters.

```{r exercise2, exercise = TRUE,  exercise.eval = TRUE}


```


```{r exercise2-solution}
starwars %>% 
  dplyr::filter(hair_color == "brown") %>% 
  dplyr::select(gender, species, homeworld) %>% 
  lapply(., table) 

```


### Resources for `dplyr`

The `dplyr` package has a number of very helpful vignettes that will show you how to use the functions that we've gone over and several other ones we haven't.

Also check out the cheatsheet for `dplyr` and `tidyr`

[dplyr Cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)


## Plotting with `ggplot2`

Another thing that **R** is known for is creating publication quality plots, graphs, and other images.  There are functions in base **R** that allow you to plot data.  Here is an example.

```{r, echo=TRUE}
plot(cars, cex = 3, pch = ".")
```

The plot above is a plot of two variables; `speed` along the x axis and `dist` along the y axis.  You can see that the plot isn't very interesting.  **R** allows for advanced customization of plots.  We can change almost anything about the plot using code, but the code isn't very easy to use.  For example, the argument for changing the size of the points is `cex` and the argument for changing the shape is `pch`. Not very intuitive.  You'd have to look at the `help()` file for plot and even then, all of the customization functions aren't there.

Because arguments aren't intuitive, Hadely Wickham created one of the most popular packages for **R** called `ggplot2` which uses the grammar of graphics (hence gg).  It's so popular that if you use *RStuido* the package is already loaded.  The `ggplot2` package uses facets to build a plot.  

```{r, echo=T}
dat <- data.frame(
  time = factor(c("Lunch","Dinner"), levels=c("Lunch","Dinner")),
  total_bill = c(14.89, 17.23)
)

# Very basic bar graph
ggplot(data=dat, aes(x=time, y=total_bill)) +
    geom_bar(stat="identity")


# Map the time of day to different fill colors
ggplot(data=dat, aes(x=time, y=total_bill, fill=time)) +
    geom_bar(stat="identity")

## This would have the same result as above
# ggplot(data=dat, aes(x=time, y=total_bill)) +
#    geom_bar(aes(fill=time), stat="identity")


# Add a black outline
ggplot(data=dat, aes(x=time, y=total_bill, fill=time)) +
    geom_bar(colour="black", stat="identity")


# No legend, since the information is redundant
ggplot(data=dat, aes(x=time, y=total_bill, fill=time)) +
    geom_bar(colour="black", stat="identity") +
    guides(fill=FALSE)
```

In the code above, we created a very simple dataframe using the `data.frame()` function.  The first plot is a very basic bar plot.  First we call the `ggplot()` function.  The first argument in the function is `dat` which is the dataframe from which we will be referencing variables.  The second argument is a call to the `aes()` function.  `aes` stands for aesthetics.  In this function we specify the variables for the `x` and `y` axes.  This is the first facet--the data.  We then use the `+` to indicate a second facet to our plot.  The `+` here serves a similar function as the `%>%` symbol in `dplyr`.  The only difference is we aren't piping, we are adding to previous commands.  The next facet is the `geom_bar()` function which indicates we want a bar plot.  The argument `stat = "identity"` indicates we want to display the value of the data.  If we didn't use the argument, by default it would have used the frequencies of the `x` variable which we don't want.  

The second plot is the same as the first except we are providing different colors for the different values of `time` by adding the `fill` argument to the `aes` function.  Because we specified that `time` as a factor, `ggplot2` while auto assign colors to each level of the factor. Also, because we specified the `fill` argument, `ggplot2` created a key showing what each color represents.

The third plot adds a border around each bar by specifying the `color` argument in the `geom_bar()` function.  

The fourth plot removes the key by adding the `guide()` function and assigning the `fill` argument to false.  Essentially this overrides the default behavior of automatically creating a key when we specified the `fill` argument in the `aes()` function.  

###Practicing `ggplot2`

Using the space below create a scatter plot using `ggplot2` with data from the starwars dataframe. Put `height` on the y-axis and `mass` on the x-axis.  HINT: Google "scatter plot ggplot2"

```{r exercise2, exercise = TRUE,  exercise.eval = TRUE}


```


```{r exercise2-solution}
ggplot(data = starwars, aes(x = mass, y = height)) +
  geom_point(color = "red")

```

***

There are a number of faceting options that you can use, but we aren't going to go over them all here.  Here are a couple references to getting started with `ggplot2`:

http://www.sthda.com/english/wiki/ggplot2-barplots-quick-start-guide-r-software-and-data-visualization

http://www.cookbook-r.com/Graphs/Bar_and_line_graphs_(ggplot2)/

http://r4ds.had.co.nz/data-visualisation.html

## **RStudio**

Up to this point we have only been using **RStudio** passively.  Essentially, we have just been running **R** within the **RStuido** environment.  **RStudio** has a whole host of features that make it useful for creating scholarly work.  

Up to this point we have been writing code in **R** scripts which are saved as .R files.  These are very basic text files.  **RStudio** has a different type file that you can use to write code called a .Rmd file. This file is an R Markdown file and it uses a package called `rmarkdown`.  

### R Markdown

R Markdown is an authoring format for the creation of dynamic documents. Dynamic documents combine simple markdown text with code and output to create documents that are completely reproducible. Users can annotate code and output and have both displayed in a single document sequentially.  Markdown text and **R** code are written in a .Rmd file which is opened by clicking File -> New File -> R Markdown.

After you write your code in the .Rmd file, click "Knit HTML" or select the output style you want to create the output document.  Each time the document is produced the syntax is compiled.  Documents cannot be produced when there are syntax errors.  Output formats include PDF, HTML, MS Word, and several others.  

Recent updates to R Markdown improve its functionality.  Previously, if you just wanted to run the code, you had to run each section of syntax (called a chunk) separately.  New options allow the user to run all the code ignoring markdown text or just a specific chunk with the click of a button.


### Example code

In R Markdown, annotations are separated from R syntax

This code adds two and two together, assigns it to the object "x", and outputs the value of "x"


```r
x <- 2 + 2
x
```

```
[1] 4
```

Each chunk is run sequentially and can have separate options for output such as caching, whether or not to evaluate syntax, or changing the size of figures.


## R Markdown Resources

[Reference Guide](https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf)

[Cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf)

http://www.stat.cmu.edu/~cshalizi/rmarkdown/

## R Markdown Reproducible Reports

- Can use R Markdown to create:
  - Statistical reports
  - Slideshow presentations
  - Tables
  - Manuscripts
  - Grants 

- Final products can be updated with changes to code instead of transcribing values

- Use "params" to change frequently referenced elements/objects

- Can setup a template

## Putting it all together

Learning **R** and **Rstudio** is easier if we can practice.  Let's open **RStudio** and make a RMarkdown document and read in data from this file https://raw.githubusercontent.com/vtmacox/teachr/master/data.csv.  This is made up data that looks at cholesterol levels and several variables that are related to cholesterol including hours of exercise, servings of fruit and vegetables, age, and if a person was taking cholesterol medication.

In the markdown document, create separate chunks for the following code objectives:
- Read in data
- Assign proper data types to each variable
- Recode the value `9` as `NA` for the `anxiety` variable
- Get the descriptive statistics for each variable (except for the `id` variable)
    + You choose which descriptives you want to show
- Create two plots 
    + A bar plot with `chol` on the y-axis and `med` on the x-axis (try giving proper labels to the axes)
    + A scatter plot with `chol` on the y-axis and `age` on the x-axis (try adding a regression line to this plot)
- Create a regression table using `chol` as the dependent variable and `exer`, `fv`, `age`, and `med` as the independent variables
    + HINT: You will need the `lm()` function to do the analysis, the `summary()` to get the results.
    + Try using the `knitr::kable()` function or the `pander::pander()` function to format and display the results.

When you finish your code, create an HTML or Word document with the results.
    
I purposely didn't provide a lot of help here, because I want you to try to figure out how to do this yourself.  Use a combination of Googling and the `help()` function.  The idea isn't so much that you know how to do these tasks, but that you know how to learn how to do them.


## Tidy data

Now that you've learned some Advanced R techniques. It's time to learn how data need to be formatted in order to analyze it.  Under most conditions, you want your data to be "tidy".  Tidy data is a term made popular by Hadely Wickham (creator of `dplyr` and `ggplot2`).  There are 3 principles of tidy data:

1. Each variable forms a column
2. Each observation forms a row
3. Each type of observational unit forms a table

For prospective data (and some retrospective data) ensuring your data is tidy is all about how you structure your data.  If you are making your own database it should be tidy, otherwise your analyst will have to do a lot of work to clean it (and they'll hate you).  

Let's look at this example :

```{r preg, results="asis"}
preg <- data.frame(name = c("John Smith", "Jane Doe", "Mary Johnson"), treatmenta = c(NA, 4, 6), treatmentb = c(18,1,7))

knitr::kable(preg)

```



```{r case-quiz}
quiz(
  question("Why isn't this data tidy",
    answer("Columns don't form variables"),
    answer("Multiple observations per row", correct = TRUE)
  )
)
```

What would this dataset look like if it was tidy? 

```{r, echo = TRUE, exercise.setup = "obese"}
preg2 <- preg %>% 
  tidyr::gather(treatment, n, treatmenta:treatmentb) %>%
  dplyr::mutate(treatment = gsub("treatment", "", treatment)) %>%
  dplyr::arrange(name, treatment)

preg2
```

Now we have tidy data.

In the code above we use the `gather()` function to turn `treatmenta` and `treatmentb` into two variables called `treatment` and `n`, where `treatment` indicates treatment a or treatment b, and `n` is the value of that treatment.  We then use the `mutate()` function to recode the `treatment` variable so we only have values of `a` and `b`.  The `gsub()` function substitutes any instance of "treatment" in the character variable `treatment` with nothing (essentially removing those instance).  The first argument is the string you want to substitute.  The second argument is the string (or number) you want to replace it with.  In this instance `""` means we want to replace it with nothing.  The third argument is the variable you want to search in and make the substitutions.  The final line of code uses the `arrange()` function from `dplyr`.  This arranges the data by name first (alphabetically) and treatment second (also alphabetically).

This format is ideal for data analysis because it is easier to deal with data in long format than wide format.  We can subset the data to include the observations that we need if we only want to look at certain observations.  But if we wanted to perform a recode for the treatment values if it was wide, we would have to write code to recode both variables.  Imagine if you have more than two observations.  This would take a very long time.  The other reason is, many statistical models where we want to look at multiple observations require the data to be in long format.  